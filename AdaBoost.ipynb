{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdaBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3ZZ/xVBB7J64ZDODdCvCL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangxs131/Machine_learning_notebook/blob/main/AdaBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##编写Adaboost\n",
        "\n",
        "为了加深adaboost的算法隐形和记忆，需要进行编写程序实现"
      ],
      "metadata": {
        "id": "3VdLOV4Q5o6w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "QTyCt7Mi0xC7",
        "outputId": "d94c399a-6430-48ed-86e1-713c67576f44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#加载简单数据\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def loadSimpData():\n",
        "  datMat = np.matrix([[ 1. ,  2.1],\n",
        "        [ 1.5,  1.6],\n",
        "        [ 1.3,  1. ],\n",
        "        [ 1. ,  1. ],\n",
        "        [ 2. ,  1. ]])\n",
        "  classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
        "  return datMat,classLabels\n",
        "\n",
        "#可视化二分类数据\n",
        "\n",
        "def showData(dataMat,labelMat):\n",
        "  data_plus=[]\n",
        "  data_minus=[]\n",
        "  for i in range(len(dataMat)):\n",
        "    if labelMat[i]>0:\n",
        "      data_plus.append(dataMat[i])\n",
        "    else:\n",
        "      data_minus.append(dataMat[i])\n",
        "    \n",
        "  plt.scatter(np.transpose(np.array(data_plus)[0]),np.transpose(np.array(data_plus)[1]))\n",
        "  plt.scatter(np.transpose(np.array(data_minus)[0]),np.transpose(np.array(data_minus)[1]))\n",
        "  plt.show()\n",
        "\n",
        "data,label=loadSimpData()\n",
        "showData(data,label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#构建单层决策树分类器，根据阈值分类\n",
        "\n",
        "def stumpClassify(data,dim,thresh,flag):\n",
        "  ret=np.ones((data.shape[0],1))\n",
        "\n",
        "  if flag=='lt':\n",
        "    ret[data[:,dim]<=thresh]=-1.0\n",
        "  else:\n",
        "    ret[data[:,dim]>thresh]=-1.0\n",
        "  return ret\n",
        "\n",
        "def buildstump(data,label,D):\n",
        "    dataMatrix = np.mat(data); labelMat = np.mat(label).T\n",
        "    m,n = np.shape(dataMatrix)\n",
        "    numSteps = 10.0; bestStump = {}; bestClasEst = np.mat(np.zeros((m,1)))\n",
        "    minError = float('inf')                                                        #最小误差初始化为正无穷大\n",
        "    for i in range(n):                                                            #遍历所有特征\n",
        "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max()        #找到特征中最小的值和最大值\n",
        "        stepSize = (rangeMax - rangeMin) / numSteps                                #计算步长\n",
        "        for j in range(-1, int(numSteps) + 1):                                     \n",
        "            for inequal in ['lt', 'gt']:                                          #大于和小于的情况，均遍历。lt:less than，gt:greater than\n",
        "                threshVal = (rangeMin + float(j) * stepSize)                     #计算阈值\n",
        "                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)#计算分类结果\n",
        "                errArr = np.mat(np.ones((m,1)))                                 #初始化误差矩阵\n",
        "                errArr[predictedVals == labelMat] = 0                             #分类正确的,赋值为0\n",
        "                weightedError = D.T * errArr                                      #计算误差\n",
        "                print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
        "                if weightedError < minError:                                     #找到误差最小的分类方式\n",
        "                    minError = weightedError\n",
        "                    bestClasEst = predictedVals.copy()\n",
        "                    bestStump['dim'] = i\n",
        "                    bestStump['thresh'] = threshVal\n",
        "                    bestStump['ineq'] = inequal\n",
        "    return bestStump,minError,bestClasEst\n",
        "\n",
        "#样本权重\n",
        "D=np.mat(np.ones((5,1))/5)\n",
        "bestStump,minError,bestClassEst=buildstump(data,label,D)\n",
        "\n",
        "print('bestStump:\\n', bestStump)\n",
        "print('minError:\\n', minError)\n",
        "print('bestClasEst:\\n', bestClassEst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtz6FrGt7Pyg",
        "outputId": "3487adbe-623f-485c-fadc-7250af3d5adb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split: dim 0, thresh 0.90, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 0.90, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.00, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.00, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.10, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.10, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.20, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.20, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.30, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 0, thresh 1.30, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 0, thresh 1.40, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 0, thresh 1.40, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 0, thresh 1.50, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.50, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.60, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.60, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.70, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.70, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.80, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.80, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.90, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.90, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 2.00, thresh ineqal: lt, the weighted error is 0.600\n",
            "split: dim 0, thresh 2.00, thresh ineqal: gt, the weighted error is 0.400\n",
            "split: dim 1, thresh 0.89, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 0.89, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 1.00, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.00, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.11, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.11, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.22, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.22, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.33, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.33, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.44, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.44, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.55, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.55, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.66, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 1.66, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 1.77, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 1.77, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 1.88, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 1.88, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 1.99, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 1.99, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 2.10, thresh ineqal: lt, the weighted error is 0.600\n",
            "split: dim 1, thresh 2.10, thresh ineqal: gt, the weighted error is 0.400\n",
            "bestStump:\n",
            " {'dim': 0, 'thresh': 1.3, 'ineq': 'lt'}\n",
            "minError:\n",
            " [[0.2]]\n",
            "bestClasEst:\n",
            " [[-1.]\n",
            " [ 1.]\n",
            " [-1.]\n",
            " [-1.]\n",
            " [ 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#加上adaboost进行加权分类器\n",
        "\n",
        "def adaBoostTrain(data,label,numIt=40):\n",
        "  weakClassArr=[]\n",
        "  m=data.shape[0]\n",
        "  D=np.mat(np.ones((m,1))/m)\n",
        "  aggClassEst=np.mat(np.zeros((m,1)))\n",
        "\n",
        "  for i in range(numIt):\n",
        "    bestStump, error, classEst = buildstump(data, label, D)     #构建单层决策树\n",
        "    print(\"D:\",D.T)\n",
        "    alpha = float(0.5 * np.log((1.0 - error) / max(error, 1e-16)))         #计算弱学习算法权重alpha,使error不等于0,因为分母不能为0\n",
        "    bestStump['alpha'] = alpha                                          #存储弱学习算法权重\n",
        "    weakClassArr.append(bestStump)                                      #存储单层决策树\n",
        "    print(\"classEst: \", classEst.T)\n",
        "    expon = np.multiply(-1 * alpha * np.mat(label).T, classEst)     #计算e的指数项\n",
        "    D = np.multiply(D, np.exp(expon))                                      \n",
        "    D = D / D.sum()                                                        #根据样本权重公式，更新样本权重\n",
        "    #计算AdaBoost误差，当误差为0的时候，退出循环\n",
        "    aggClassEst += alpha * classEst                                 \n",
        "    print(\"aggClassEst: \", aggClassEst.T)\n",
        "    aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(label).T, np.ones((m,1)))     #计算误差\n",
        "    errorRate = aggErrors.sum() / m\n",
        "    print(\"total error: \", errorRate)\n",
        "\n",
        "    if errorRate == 0.0: \n",
        "      break                                             #误差为0，退出循环\n",
        "  return weakClassArr, aggClassEst\n",
        "\n",
        "weekClassArr,aggClassEst=adaBoostTrain(data,label)\n",
        "print(weekClassArr)\n",
        "print(aggClassEst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_LzcvIt8rr2",
        "outputId": "c7ca8c71-14c0-4018-8f09-d887ec32c206"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split: dim 0, thresh 0.90, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 0.90, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.00, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.00, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.10, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.10, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.20, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.20, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.30, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 0, thresh 1.30, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 0, thresh 1.40, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 0, thresh 1.40, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 0, thresh 1.50, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.50, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.60, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.60, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.70, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.70, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.80, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.80, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 1.90, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 0, thresh 1.90, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 0, thresh 2.00, thresh ineqal: lt, the weighted error is 0.600\n",
            "split: dim 0, thresh 2.00, thresh ineqal: gt, the weighted error is 0.400\n",
            "split: dim 1, thresh 0.89, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 0.89, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 1.00, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.00, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.11, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.11, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.22, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.22, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.33, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.33, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.44, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.44, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.55, thresh ineqal: lt, the weighted error is 0.200\n",
            "split: dim 1, thresh 1.55, thresh ineqal: gt, the weighted error is 0.800\n",
            "split: dim 1, thresh 1.66, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 1.66, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 1.77, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 1.77, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 1.88, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 1.88, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 1.99, thresh ineqal: lt, the weighted error is 0.400\n",
            "split: dim 1, thresh 1.99, thresh ineqal: gt, the weighted error is 0.600\n",
            "split: dim 1, thresh 2.10, thresh ineqal: lt, the weighted error is 0.600\n",
            "split: dim 1, thresh 2.10, thresh ineqal: gt, the weighted error is 0.400\n",
            "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
            "classEst:  [[-1.  1. -1. -1.  1.]]\n",
            "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
            "total error:  0.2\n",
            "split: dim 0, thresh 0.90, thresh ineqal: lt, the weighted error is 0.250\n",
            "split: dim 0, thresh 0.90, thresh ineqal: gt, the weighted error is 0.750\n",
            "split: dim 0, thresh 1.00, thresh ineqal: lt, the weighted error is 0.625\n",
            "split: dim 0, thresh 1.00, thresh ineqal: gt, the weighted error is 0.375\n",
            "split: dim 0, thresh 1.10, thresh ineqal: lt, the weighted error is 0.625\n",
            "split: dim 0, thresh 1.10, thresh ineqal: gt, the weighted error is 0.375\n",
            "split: dim 0, thresh 1.20, thresh ineqal: lt, the weighted error is 0.625\n",
            "split: dim 0, thresh 1.20, thresh ineqal: gt, the weighted error is 0.375\n",
            "split: dim 0, thresh 1.30, thresh ineqal: lt, the weighted error is 0.500\n",
            "split: dim 0, thresh 1.30, thresh ineqal: gt, the weighted error is 0.500\n",
            "split: dim 0, thresh 1.40, thresh ineqal: lt, the weighted error is 0.500\n",
            "split: dim 0, thresh 1.40, thresh ineqal: gt, the weighted error is 0.500\n",
            "split: dim 0, thresh 1.50, thresh ineqal: lt, the weighted error is 0.625\n",
            "split: dim 0, thresh 1.50, thresh ineqal: gt, the weighted error is 0.375\n",
            "split: dim 0, thresh 1.60, thresh ineqal: lt, the weighted error is 0.625\n",
            "split: dim 0, thresh 1.60, thresh ineqal: gt, the weighted error is 0.375\n",
            "split: dim 0, thresh 1.70, thresh ineqal: lt, the weighted error is 0.625\n",
            "split: dim 0, thresh 1.70, thresh ineqal: gt, the weighted error is 0.375\n",
            "split: dim 0, thresh 1.80, thresh ineqal: lt, the weighted error is 0.625\n",
            "split: dim 0, thresh 1.80, thresh ineqal: gt, the weighted error is 0.375\n",
            "split: dim 0, thresh 1.90, thresh ineqal: lt, the weighted error is 0.625\n",
            "split: dim 0, thresh 1.90, thresh ineqal: gt, the weighted error is 0.375\n",
            "split: dim 0, thresh 2.00, thresh ineqal: lt, the weighted error is 0.750\n",
            "split: dim 0, thresh 2.00, thresh ineqal: gt, the weighted error is 0.250\n",
            "split: dim 1, thresh 0.89, thresh ineqal: lt, the weighted error is 0.250\n",
            "split: dim 1, thresh 0.89, thresh ineqal: gt, the weighted error is 0.750\n",
            "split: dim 1, thresh 1.00, thresh ineqal: lt, the weighted error is 0.125\n",
            "split: dim 1, thresh 1.00, thresh ineqal: gt, the weighted error is 0.875\n",
            "split: dim 1, thresh 1.11, thresh ineqal: lt, the weighted error is 0.125\n",
            "split: dim 1, thresh 1.11, thresh ineqal: gt, the weighted error is 0.875\n",
            "split: dim 1, thresh 1.22, thresh ineqal: lt, the weighted error is 0.125\n",
            "split: dim 1, thresh 1.22, thresh ineqal: gt, the weighted error is 0.875\n",
            "split: dim 1, thresh 1.33, thresh ineqal: lt, the weighted error is 0.125\n",
            "split: dim 1, thresh 1.33, thresh ineqal: gt, the weighted error is 0.875\n",
            "split: dim 1, thresh 1.44, thresh ineqal: lt, the weighted error is 0.125\n",
            "split: dim 1, thresh 1.44, thresh ineqal: gt, the weighted error is 0.875\n",
            "split: dim 1, thresh 1.55, thresh ineqal: lt, the weighted error is 0.125\n",
            "split: dim 1, thresh 1.55, thresh ineqal: gt, the weighted error is 0.875\n",
            "split: dim 1, thresh 1.66, thresh ineqal: lt, the weighted error is 0.250\n",
            "split: dim 1, thresh 1.66, thresh ineqal: gt, the weighted error is 0.750\n",
            "split: dim 1, thresh 1.77, thresh ineqal: lt, the weighted error is 0.250\n",
            "split: dim 1, thresh 1.77, thresh ineqal: gt, the weighted error is 0.750\n",
            "split: dim 1, thresh 1.88, thresh ineqal: lt, the weighted error is 0.250\n",
            "split: dim 1, thresh 1.88, thresh ineqal: gt, the weighted error is 0.750\n",
            "split: dim 1, thresh 1.99, thresh ineqal: lt, the weighted error is 0.250\n",
            "split: dim 1, thresh 1.99, thresh ineqal: gt, the weighted error is 0.750\n",
            "split: dim 1, thresh 2.10, thresh ineqal: lt, the weighted error is 0.750\n",
            "split: dim 1, thresh 2.10, thresh ineqal: gt, the weighted error is 0.250\n",
            "D: [[0.5   0.125 0.125 0.125 0.125]]\n",
            "classEst:  [[ 1.  1. -1. -1. -1.]]\n",
            "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
            "total error:  0.2\n",
            "split: dim 0, thresh 0.90, thresh ineqal: lt, the weighted error is 0.143\n",
            "split: dim 0, thresh 0.90, thresh ineqal: gt, the weighted error is 0.857\n",
            "split: dim 0, thresh 1.00, thresh ineqal: lt, the weighted error is 0.357\n",
            "split: dim 0, thresh 1.00, thresh ineqal: gt, the weighted error is 0.643\n",
            "split: dim 0, thresh 1.10, thresh ineqal: lt, the weighted error is 0.357\n",
            "split: dim 0, thresh 1.10, thresh ineqal: gt, the weighted error is 0.643\n",
            "split: dim 0, thresh 1.20, thresh ineqal: lt, the weighted error is 0.357\n",
            "split: dim 0, thresh 1.20, thresh ineqal: gt, the weighted error is 0.643\n",
            "split: dim 0, thresh 1.30, thresh ineqal: lt, the weighted error is 0.286\n",
            "split: dim 0, thresh 1.30, thresh ineqal: gt, the weighted error is 0.714\n",
            "split: dim 0, thresh 1.40, thresh ineqal: lt, the weighted error is 0.286\n",
            "split: dim 0, thresh 1.40, thresh ineqal: gt, the weighted error is 0.714\n",
            "split: dim 0, thresh 1.50, thresh ineqal: lt, the weighted error is 0.357\n",
            "split: dim 0, thresh 1.50, thresh ineqal: gt, the weighted error is 0.643\n",
            "split: dim 0, thresh 1.60, thresh ineqal: lt, the weighted error is 0.357\n",
            "split: dim 0, thresh 1.60, thresh ineqal: gt, the weighted error is 0.643\n",
            "split: dim 0, thresh 1.70, thresh ineqal: lt, the weighted error is 0.357\n",
            "split: dim 0, thresh 1.70, thresh ineqal: gt, the weighted error is 0.643\n",
            "split: dim 0, thresh 1.80, thresh ineqal: lt, the weighted error is 0.357\n",
            "split: dim 0, thresh 1.80, thresh ineqal: gt, the weighted error is 0.643\n",
            "split: dim 0, thresh 1.90, thresh ineqal: lt, the weighted error is 0.357\n",
            "split: dim 0, thresh 1.90, thresh ineqal: gt, the weighted error is 0.643\n",
            "split: dim 0, thresh 2.00, thresh ineqal: lt, the weighted error is 0.857\n",
            "split: dim 0, thresh 2.00, thresh ineqal: gt, the weighted error is 0.143\n",
            "split: dim 1, thresh 0.89, thresh ineqal: lt, the weighted error is 0.143\n",
            "split: dim 1, thresh 0.89, thresh ineqal: gt, the weighted error is 0.857\n",
            "split: dim 1, thresh 1.00, thresh ineqal: lt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.00, thresh ineqal: gt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.11, thresh ineqal: lt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.11, thresh ineqal: gt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.22, thresh ineqal: lt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.22, thresh ineqal: gt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.33, thresh ineqal: lt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.33, thresh ineqal: gt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.44, thresh ineqal: lt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.44, thresh ineqal: gt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.55, thresh ineqal: lt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.55, thresh ineqal: gt, the weighted error is 0.500\n",
            "split: dim 1, thresh 1.66, thresh ineqal: lt, the weighted error is 0.571\n",
            "split: dim 1, thresh 1.66, thresh ineqal: gt, the weighted error is 0.429\n",
            "split: dim 1, thresh 1.77, thresh ineqal: lt, the weighted error is 0.571\n",
            "split: dim 1, thresh 1.77, thresh ineqal: gt, the weighted error is 0.429\n",
            "split: dim 1, thresh 1.88, thresh ineqal: lt, the weighted error is 0.571\n",
            "split: dim 1, thresh 1.88, thresh ineqal: gt, the weighted error is 0.429\n",
            "split: dim 1, thresh 1.99, thresh ineqal: lt, the weighted error is 0.571\n",
            "split: dim 1, thresh 1.99, thresh ineqal: gt, the weighted error is 0.429\n",
            "split: dim 1, thresh 2.10, thresh ineqal: lt, the weighted error is 0.857\n",
            "split: dim 1, thresh 2.10, thresh ineqal: gt, the weighted error is 0.143\n",
            "D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
            "classEst:  [[1. 1. 1. 1. 1.]]\n",
            "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
            "total error:  0.0\n",
            "[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453}, {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565}, {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]\n",
            "[[ 1.17568763]\n",
            " [ 2.56198199]\n",
            " [-0.77022252]\n",
            " [-0.77022252]\n",
            " [ 0.61607184]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##对测试集进行预测\n",
        "\n",
        "def adaClassify(test_data,classifier):\n",
        "  data=np.array(test_data)\n",
        "  m=data.shape[0]\n",
        "\n",
        "  aggClassEst=np.mat(np.zeros((m,1)))\n",
        "  for i in range(len(classifier)):\n",
        "    classEst=stumpClassify(data,classifier[i]['dim'],classifier[i]['thresh'],classifier[i]['ineq'])\n",
        "    aggClassEst+=classifier[i]['alpha']*classEst\n",
        "  return np.sign(aggClassEst)\n",
        "\n",
        "result=adaClassify([[0,0],[5,5]],weekClassArr)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9xcp-YOCarf",
        "outputId": "cd38be05-16ba-4caa-c44b-6fdf726fb075"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[-1.],\n",
              "        [ 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#在其他数据集进行实验\n",
        "!wget https://raw.githubusercontent.com/Jack-Cherish/Machine-Learning/master/AdaBoost/horseColicTraining2.txt\n",
        "!wget https://raw.githubusercontent.com/Jack-Cherish/Machine-Learning/master/AdaBoost/horseColicTest2.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHjg2wKMFCIm",
        "outputId": "e0388df5-74a9-4b15-87f0-a4bdce100204"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-04 08:00:37--  https://raw.githubusercontent.com/Jack-Cherish/Machine-Learning/master/AdaBoost/horseColicTraining2.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60479 (59K) [text/plain]\n",
            "Saving to: ‘horseColicTraining2.txt.1’\n",
            "\n",
            "\r          horseColi   0%[                    ]       0  --.-KB/s               \rhorseColicTraining2 100%[===================>]  59.06K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-05-04 08:00:37 (15.8 MB/s) - ‘horseColicTraining2.txt.1’ saved [60479/60479]\n",
            "\n",
            "--2022-05-04 08:00:37--  https://raw.githubusercontent.com/Jack-Cherish/Machine-Learning/master/AdaBoost/horseColicTest2.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13547 (13K) [text/plain]\n",
            "Saving to: ‘horseColicTest2.txt’\n",
            "\n",
            "horseColicTest2.txt 100%[===================>]  13.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-04 08:00:37 (92.4 MB/s) - ‘horseColicTest2.txt’ saved [13547/13547]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loadDataSet(fileName):\n",
        "    numFeat = len((open(fileName).readline().split('\\t')))\n",
        "    dataMat = []; labelMat = []\n",
        "    fr = open(fileName)\n",
        "    for line in fr.readlines():\n",
        "        lineArr = []\n",
        "        curLine = line.strip().split('\\t')\n",
        "        for i in range(numFeat - 1):\n",
        "            lineArr.append(float(curLine[i]))\n",
        "        dataMat.append(lineArr)\n",
        "        labelMat.append(float(curLine[-1]))\n",
        "    return dataMat, labelMat\n",
        "\n",
        "data_horse,label_horse=loadDataSet('/content/horseColicTraining2.txt')\n",
        "test_data,test_label=loadDataSet('/content/horseColicTest2.txt')\n",
        "\n",
        "weekClassifier,aggClass=adaBoostTrain(np.mat(data_horse),label_horse,100)\n",
        "print(weekClassifier)\n",
        "\n",
        "predictions=adaClassify(data_horse,weekClassArr)\n",
        "errArr=np.mat(np.ones((len(data_horse),1)))\n",
        "print(\"train_dataset error rate is {:.2f}%\".format(float(errArr[predictions!=np.mat(label_horse).T].sum()/len(data_horse)*100)))\n",
        "\n",
        "predictions=adaClassify(test_data,weekClassArr)\n",
        "errArr_test=np.mat(np.ones((len(test_data),1)))\n",
        "print(\"test_dataset error rate is {:.2f}%\".format(float(errArr_test[predictions!=np.mat(test_label).T].sum()/len(test_data)*100)))"
      ],
      "metadata": {
        "id": "xVyCbceGFJCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##sklearn 实现adaBoostClassifier\n",
        "\n",
        "参数设置：\n",
        "*      base_estimator 基础分类器，默认决策树，可以选择cart，或MLP\n",
        "*      algorithm 算法，默认SAMME.R 决定弱学习器权重度量\n",
        "*      n_estimators  最大迭代次数\n",
        "*      learning_rate  每个弱学习器，权重衰减系数"
      ],
      "metadata": {
        "id": "MzD1Vm77H5RC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#对上面的数据集进行实验\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bdt=AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),algorithm='SAMME',n_estimators=10)\n",
        "bdt.fit(data_horse,label_horse)\n",
        "\n",
        "predictions=bdt.predict(data_horse)\n",
        "errArr=np.mat(np.ones((len(data_horse),1)))\n",
        "print(\"train_dataset error rate is {:.2f}%\".format(float(errArr[predictions!=label_horse].sum()/len(data_horse)*100)))\n",
        "\n",
        "predictions_2=bdt.predict(test_data)\n",
        "errArr_test=np.mat(np.ones((len(test_data),1)))\n",
        "print(\"test_dataset error rate is {:.2f}%\".format(float(errArr_test[predictions_2!=test_label].sum()/len(test_data)*100)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfQBX1AmJGqG",
        "outputId": "aedd9d68-71a0-4e1c-ca95-acd14e26cd3b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset error rate is 16.05%\n",
            "test_dataset error rate is 17.91%\n"
          ]
        }
      ]
    }
  ]
}